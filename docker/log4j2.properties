# Set everything to ERROR level by default
rootLogger = WARN, console
 
# Console appender configuration
appender.console.type = Console
appender.console.name = console
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n%ex

appender.logfile.type = File
appender.logfile.name = logfile
appender.logfile.fileName=/opt/sparkbench/logs/log4j2.log
appender.logfile.layout.type=PatternLayout
appender.logfile.layout.pattern=%d{UNIX_MILLIS} [%t] %level %logger{36} - %msg%n

loggers = org.apache.spark.scheduler.cluster.k8s, org.apache.spark.scheduler.dynalloc

logger.org.apache.spark.scheduler.cluster.k8s.name = org.apache.spark.scheduler.cluster.k8s
logger.org.apache.spark.scheduler.cluster.k8s.level = INFO
logger.org.apache.spark.scheduler.cluster.k8s.appenderRef.stdout.ref = logfile
logger.org.apache.spark.scheduler.cluster.k8s.additivity = true

# Set INFO level for Dynamic Allocation Manager to track executor events
logger.org.apache.spark.scheduler.dynalloc.name = org.apache.spark.scheduler.dynalloc
logger.org.apache.spark.scheduler.dynalloc.level = INFO
logger.org.apache.spark.scheduler.dynalloc.appenderRef.stdout.ref = logfile
logger.org.apache.spark.scheduler.dynalloc.additivity = true
