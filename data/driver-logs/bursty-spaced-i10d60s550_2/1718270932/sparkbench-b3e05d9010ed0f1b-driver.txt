Files  local:///opt/sparkbench/sparkbench_2.12-1.0.jar from /opt/sparkbench/sparkbench_2.12-1.0.jar to /opt/spark/work-dir/./sparkbench_2.12-1.0.jar
24/06/13 09:28:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/06/13 09:28:16 INFO HiveConf: Found configuration file null
24/06/13 09:28:17 INFO SparkContext: Running Spark version 3.4.1
24/06/13 09:28:17 INFO ResourceUtils: ==============================================================
24/06/13 09:28:17 INFO ResourceUtils: No custom resources configured for spark.driver.
24/06/13 09:28:17 INFO ResourceUtils: ==============================================================
24/06/13 09:28:17 INFO SparkContext: Submitted application: Data Generator
24/06/13 09:28:17 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 24576, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/06/13 09:28:17 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
24/06/13 09:28:17 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/06/13 09:28:17 INFO SecurityManager: Changing view acls to: spark,lennart
24/06/13 09:28:17 INFO SecurityManager: Changing modify acls to: spark,lennart
24/06/13 09:28:17 INFO SecurityManager: Changing view acls groups to: 
24/06/13 09:28:17 INFO SecurityManager: Changing modify acls groups to: 
24/06/13 09:28:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, lennart; groups with view permissions: EMPTY; users with modify permissions: spark, lennart; groups with modify permissions: EMPTY
24/06/13 09:28:17 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
24/06/13 09:28:17 INFO SparkEnv: Registering MapOutputTracker
24/06/13 09:28:17 INFO SparkEnv: Registering BlockManagerMaster
24/06/13 09:28:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/06/13 09:28:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/06/13 09:28:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/06/13 09:28:17 INFO DiskBlockManager: Created local directory at /var/data/spark-c92adb63-c6c4-473e-8c3f-0687a338164d/blockmgr-c14fdae0-99af-48e9-8663-121421181b6d
24/06/13 09:28:17 INFO MemoryStore: MemoryStore started with capacity 11.8 GiB
24/06/13 09:28:17 INFO SparkEnv: Registering OutputCommitCoordinator
24/06/13 09:28:18 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/06/13 09:28:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/06/13 09:28:18 INFO SparkContext: Added JAR local:/opt/sparkbench/sparkbench_2.12-1.0.jar at file:/opt/sparkbench/sparkbench_2.12-1.0.jar with timestamp 1718270897189
24/06/13 09:28:18 WARN SparkContext: The JAR local:///opt/sparkbench/sparkbench_2.12-1.0.jar at file:/opt/sparkbench/sparkbench_2.12-1.0.jar has been added already. Overwriting of added jar is not supported in the current version.
24/06/13 09:28:18 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
24/06/13 09:28:20 INFO ExecutorPodsAllocator: Going to request 3 executors from Kubernetes for ResourceProfile Id: 0, target: 5, known: 0, sharedSlotFromPendingPods: 2147483647.
24/06/13 09:28:20 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
24/06/13 09:28:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
24/06/13 09:28:20 INFO NettyBlockTransferService: Server created on sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc 10.244.5.57:7079
24/06/13 09:28:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/06/13 09:28:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc, 7079, None)
24/06/13 09:28:20 INFO BlockManagerMasterEndpoint: Registering block manager sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc:7079 with 11.8 GiB RAM, BlockManagerId(driver, sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc, 7079, None)
24/06/13 09:28:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc, 7079, None)
24/06/13 09:28:20 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/13 09:28:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc, 7079, None)
24/06/13 09:28:20 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/13 09:28:20 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/13 09:28:21 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
24/06/13 09:28:21 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
24/06/13 09:28:21 INFO MetricsSystemImpl: s3a-file-system metrics system started
24/06/13 09:28:21 INFO ExecutorPodsAllocator: Going to request 2 executors from Kubernetes for ResourceProfile Id: 0, target: 5, known: 3, sharedSlotFromPendingPods: 2147483644.
24/06/13 09:28:21 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
24/06/13 09:28:21 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/13 09:28:21 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/13 09:28:22 INFO SingleEventLogFileWriter: Logging events to s3a://logs/spark-events/spark-bc7d319c576747f396f70535697de41e.inprogress
24/06/13 09:28:22 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to spark-events/spark-bc7d319c576747f396f70535697de41e.inprogress. This is unsupported
24/06/13 09:28:25 WARN TransportChannelHandler: Exception in connection from /10.244.9.68:54164
java.io.IOException: Connection reset by peer
	at java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.read(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.read(Unknown Source)
	at java.base/sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Unknown Source)
24/06/13 09:28:25 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: No executor found for 10.244.9.68:54164
24/06/13 09:28:25 WARN TransportChannelHandler: Exception in connection from /10.244.11.76:51716
java.io.IOException: Connection reset by peer
	at java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.read(Unknown Source)
	at java.base/sun.nio.ch.IOUtil.read(Unknown Source)
	at java.base/sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Unknown Source)
24/06/13 09:28:25 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: No executor found for 10.244.11.76:51716
24/06/13 09:28:25 INFO SparkContext: Invoking stop() from shutdown hook
24/06/13 09:28:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/06/13 09:28:25 INFO SparkUI: Stopped Spark web UI at http://sparkbench-b3e05d9010ed0f1b-driver-svc.default.svc:4040
24/06/13 09:28:25 ERROR SparkContext: Error initializing SparkContext.
java.lang.IllegalStateException: Spark context stopped while waiting for backend
	at org.apache.spark.scheduler.TaskSchedulerImpl.waitBackendReady(TaskSchedulerImpl.scala:1213)
	at org.apache.spark.scheduler.TaskSchedulerImpl.postStartHook(TaskSchedulerImpl.scala:246)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:672)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2740)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)
	at Sparkbench$.main(Sparkbench.scala:10)
	at Sparkbench.main(Sparkbench.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1020)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:192)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
24/06/13 09:28:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/06/13 09:28:25 INFO SparkContext: SparkContext already stopped.
Exception in thread "main" java.lang.IllegalStateException: Spark context stopped while waiting for backend
	at org.apache.spark.scheduler.TaskSchedulerImpl.waitBackendReady(TaskSchedulerImpl.scala:1213)
	at org.apache.spark.scheduler.TaskSchedulerImpl.postStartHook(TaskSchedulerImpl.scala:246)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:672)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2740)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)
	at Sparkbench$.main(Sparkbench.scala:10)
	at Sparkbench.main(Sparkbench.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1020)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:192)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
24/06/13 09:28:25 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
24/06/13 09:28:25 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
24/06/13 09:28:25 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
24/06/13 09:28:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/06/13 09:28:26 INFO MemoryStore: MemoryStore cleared
24/06/13 09:28:26 INFO BlockManager: BlockManager stopped
24/06/13 09:28:26 INFO BlockManagerMaster: BlockManagerMaster stopped
24/06/13 09:28:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/06/13 09:28:26 INFO SparkContext: Successfully stopped SparkContext
24/06/13 09:28:26 INFO ShutdownHookManager: Shutdown hook called
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-61c8f2d9-bada-4507-b8a9-e6a561383d51
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-41454181-05e9-44d0-8ea5-78ed1f332a60
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-3d7c1924-b32e-4b1f-a25e-350b04367a13
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-c0f3613a-93a8-47cf-90f9-2b0b484a570f
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-bab4fd35-3336-4457-acc0-851e9a5d88b0
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-0cdcd4e7-f614-4fc5-8032-d2e9343ff54c
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-b00d3e16-bfac-4347-b022-6c51bdd0de75
24/06/13 09:28:26 INFO ShutdownHookManager: Deleting directory /var/data/spark-c92adb63-c6c4-473e-8c3f-0687a338164d/spark-c8379089-35c7-4b42-b14f-2b254a7a9bdb
24/06/13 09:28:26 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
24/06/13 09:28:26 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
24/06/13 09:28:26 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
