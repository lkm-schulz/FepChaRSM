Files  local:///opt/sparkbench/sparkbench_2.12-1.0.jar from /opt/sparkbench/sparkbench_2.12-1.0.jar to /opt/spark/work-dir/./sparkbench_2.12-1.0.jar
24/06/10 16:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/06/10 16:47:48 INFO HiveConf: Found configuration file null
24/06/10 16:47:48 INFO SparkContext: Running Spark version 3.4.1
24/06/10 16:47:48 INFO ResourceUtils: ==============================================================
24/06/10 16:47:48 INFO ResourceUtils: No custom resources configured for spark.driver.
24/06/10 16:47:48 INFO ResourceUtils: ==============================================================
24/06/10 16:47:48 INFO SparkContext: Submitted application: Data Generator
24/06/10 16:47:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 28672, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/06/10 16:47:48 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
24/06/10 16:47:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/06/10 16:47:48 INFO SecurityManager: Changing view acls to: spark,lennart
24/06/10 16:47:48 INFO SecurityManager: Changing modify acls to: spark,lennart
24/06/10 16:47:48 INFO SecurityManager: Changing view acls groups to: 
24/06/10 16:47:48 INFO SecurityManager: Changing modify acls groups to: 
24/06/10 16:47:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, lennart; groups with view permissions: EMPTY; users with modify permissions: spark, lennart; groups with modify permissions: EMPTY
24/06/10 16:47:48 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
24/06/10 16:47:48 INFO SparkEnv: Registering MapOutputTracker
24/06/10 16:47:48 INFO SparkEnv: Registering BlockManagerMaster
24/06/10 16:47:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/06/10 16:47:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/06/10 16:47:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/06/10 16:47:48 INFO DiskBlockManager: Created local directory at /var/data/spark-7a19ffdd-2c0e-4e66-8991-a5e39cdb224a/blockmgr-844c9509-91da-4bf1-bb3a-841263ca38bb
24/06/10 16:47:48 INFO MemoryStore: MemoryStore started with capacity 11.8 GiB
24/06/10 16:47:49 INFO SparkEnv: Registering OutputCommitCoordinator
24/06/10 16:47:49 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/06/10 16:47:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/06/10 16:47:49 INFO SparkContext: Added JAR local:/opt/sparkbench/sparkbench_2.12-1.0.jar at file:/opt/sparkbench/sparkbench_2.12-1.0.jar with timestamp 1718038068326
24/06/10 16:47:49 WARN SparkContext: The JAR local:///opt/sparkbench/sparkbench_2.12-1.0.jar at file:/opt/sparkbench/sparkbench_2.12-1.0.jar has been added already. Overwriting of added jar is not supported in the current version.
24/06/10 16:47:49 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
24/06/10 16:47:51 INFO ExecutorPodsAllocator: Going to request 3 executors from Kubernetes for ResourceProfile Id: 0, target: 3, known: 0, sharedSlotFromPendingPods: 2147483647.
24/06/10 16:47:51 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
24/06/10 16:47:51 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/10 16:47:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
24/06/10 16:47:51 INFO NettyBlockTransferService: Server created on sparkbench-dc5f2390030bb9b1-driver-svc.default.svc 10.244.2.2:7079
24/06/10 16:47:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/06/10 16:47:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sparkbench-dc5f2390030bb9b1-driver-svc.default.svc, 7079, None)
24/06/10 16:47:51 INFO BlockManagerMasterEndpoint: Registering block manager sparkbench-dc5f2390030bb9b1-driver-svc.default.svc:7079 with 11.8 GiB RAM, BlockManagerId(driver, sparkbench-dc5f2390030bb9b1-driver-svc.default.svc, 7079, None)
24/06/10 16:47:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sparkbench-dc5f2390030bb9b1-driver-svc.default.svc, 7079, None)
24/06/10 16:47:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sparkbench-dc5f2390030bb9b1-driver-svc.default.svc, 7079, None)
24/06/10 16:47:51 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/10 16:47:51 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/06/10 16:47:52 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
24/06/10 16:47:52 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
24/06/10 16:47:52 INFO MetricsSystemImpl: s3a-file-system metrics system started
24/06/10 16:47:53 INFO SingleEventLogFileWriter: Logging events to s3a://logs/spark-events/spark-d97e415d1563432a8c720e202a64218c.inprogress
24/06/10 16:47:53 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to spark-events/spark-d97e415d1563432a8c720e202a64218c.inprogress. This is unsupported
24/06/10 16:48:20 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)
Custom start time given: 1718038060
24/06/10 16:48:21 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/06/10 16:48:21 INFO SparkUI: Stopped Spark web UI at http://sparkbench-dc5f2390030bb9b1-driver-svc.default.svc:4040
24/06/10 16:48:21 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
24/06/10 16:48:21 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
24/06/10 16:48:21 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
24/06/10 16:48:21 ERROR Utils: Uncaught exception in thread kubernetes-executor-pod-polling-sync
io.fabric8.kubernetes.client.KubernetesClientException: Operation: [list]  for kind: [Pod]  with name: [null]  in namespace: [default]  failed.
	at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:159)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.list(BaseOperation.java:429)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.list(BaseOperation.java:392)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.list(BaseOperation.java:93)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsPollingSnapshotSource$PollRunnable.$anonfun$run$1(ExecutorPodsPollingSnapshotSource.scala:91)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsPollingSnapshotSource$PollRunnable.run(ExecutorPodsPollingSnapshotSource.scala:74)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.base/java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.io.InterruptedIOException
	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.waitForResult(OperationSupport.java:525)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.list(BaseOperation.java:427)
	... 11 more
Caused by: java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(Unknown Source)
	at java.base/java.util.concurrent.CompletableFuture.get(Unknown Source)
	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.waitForResult(OperationSupport.java:520)
	... 12 more
24/06/10 16:48:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/06/10 16:48:21 INFO MemoryStore: MemoryStore cleared
24/06/10 16:48:21 INFO BlockManager: BlockManager stopped
24/06/10 16:48:21 INFO BlockManagerMaster: BlockManagerMaster stopped
24/06/10 16:48:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/06/10 16:48:21 INFO SparkContext: Successfully stopped SparkContext
Exception in thread "main" java.io.FileNotFoundException: /opt/sparkbench/workloads/bursty-spaced-i5d30v1_3.csv (No such file or directory)
	at java.base/java.io.FileInputStream.open0(Native Method)
	at java.base/java.io.FileInputStream.open(Unknown Source)
	at java.base/java.io.FileInputStream.<init>(Unknown Source)
	at scala.io.Source$.fromFile(Source.scala:94)
	at scala.io.Source$.fromFile(Source.scala:79)
	at scala.io.Source$.fromFile(Source.scala:57)
	at Workload$.fromFile(Workload.scala:39)
	at Sparkbench$.main(Sparkbench.scala:40)
	at Sparkbench.main(Sparkbench.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1020)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:192)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
24/06/10 16:48:21 INFO ShutdownHookManager: Shutdown hook called
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-bbfd0d40-3524-46ff-886f-6a400aeb9fb8
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /var/data/spark-7a19ffdd-2c0e-4e66-8991-a5e39cdb224a/spark-4ff56320-b535-4449-9212-3b75d99ddd08
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-c66dacf5-e86c-4c24-98a0-f1c7a0b7b098
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-e862c965-0f23-409a-9f9a-ccaaaec8bab3
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-016f59fa-afdf-4bb4-9400-a83ccecd202e
24/06/10 16:48:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-0f869665-0207-4e6e-badf-99a46cd8a649
24/06/10 16:48:21 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
24/06/10 16:48:21 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
24/06/10 16:48:21 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
